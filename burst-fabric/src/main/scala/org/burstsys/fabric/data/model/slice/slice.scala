/* Copyright Yahoo, Licensed under the terms of the Apache 2.0 license. See LICENSE file in project root for terms. */
package org.burstsys.fabric.data.model

import java.nio.file.Path

import org.burstsys.fabric.data.model.slice.metadata.FabricSliceMetadata
import org.burstsys.fabric.data.model.slice.region._
import org.burstsys.fabric.metadata.model
import org.burstsys.fabric.metadata.model.datasource.FabricDatasource
import org.burstsys.vitals.errors._
import org.burstsys.vitals.logging._
import org.burstsys.vitals.net.getPublicHostName

import scala.language.implicitConversions

package object slice extends VitalsLogger {

  /**
   * a unique integer for each slice in a dataset generation. It is customary to have these start at zero and increment.
   * However currently there is no restriction on this. Note that this key MUST be unique and in conjunction with the
   * [[FabricGenerationHash]] must be useable by the worker cache to be 100% confident any cached datasource/sliceKey/generationHash
   * is exactly correct to serve that specific slice's data at that moment.
   */
  type FabricSliceKey = Int

  type FabricSliceCount = Int

  /**
   * this is a unique key that is generated by the store that can be used by the cell side to determine if
   * a particular generation for the same datasource can be assumed to be identical in exactly what part of the overall
   * dataset goes into each slice and how to access it. A given worker trying to satisfy
   * a request for a specific slice will use this to determine if the data it currently has matches the last
   * cold load and thus if it needs to use a fresh cold load or not. Note that a reasonably smallish count of
   * false negative matches (does NOT match but should) are not forbidden as they at worst unnecessary cold loads
   * (non optimal performance). False positives (DOES match but should not) however will result in incorrect data and
   * thus must be 100% disallowed. Each store is responsible for creating a unique
   * string that deterministically says that the last generation can be considered identical to any other. This
   * means that is data sourcing nodes go down or if any sorts of key mappings change - that change will be
   * represented by a different hash and there will never be confusion over the entire dataset of distributed
   * slices on independent workers each managing their own cache of slices.
   */
  type FabricGenerationHash = String

  /**
   * convert a discovered path to a Key
   *
   * @param path
   * @return
   */
  def pathToSlice(path: Path): FabricSliceMetadata = {
    val fileName = path.getFileName.toString.stripSuffix(s"${regionFileSuffix}")
    val components = fileName.split('_')
    try {
      val domainKey = components(0).trim.toLong
      val viewKey = components(1).trim.toLong
      val generationClock = components(2).trim.toLong
      val sliceKey = components(3).trim.toInt
      //      val sliceCount = components(4).trim.toInt
      val datasource = model.datasource.FabricDatasource(domainKey, viewKey, generationClock)
      FabricSliceMetadata(datasource, sliceKey, getPublicHostName)
    } catch safely {
      case _: Throwable =>
        log warn burstStdMsg(s"malformed (or old version) fabric data cache region file '$fileName'")
        null
    }
  }

  def sliceToFilePath(slice: FabricSliceMetadata): String = {
    val domainKey = slice.datasource.domain.domainKey
    val viewKey = slice.datasource.view.viewKey
    val generationClock = slice.datasource.view.generationClock
    val sliceKey = slice.sliceKey
    //    val sliceCount = slice.slices
    //    f"$domainKey%020d_$viewKey%020d_$generationClock%020d_$sliceKey%05d_$sliceCount%05d${region.regionFileSuffix}"
    f"$domainKey%020d_$viewKey%020d_$generationClock%020d_$sliceKey%05d${regionFileSuffix}"
  }

}
